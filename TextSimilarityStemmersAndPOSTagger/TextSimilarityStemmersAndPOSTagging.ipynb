{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Similarity, Stemmers and POS Tagging\n",
    "### Author: Kevin Okiah\n",
    "**02/23/2019**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document explores text similarity using Levenshtein distance measures, application of different NLTK Stemmers and POS tagging using StanfordPos Tagger,NLTK POS Tagger and Unigram Tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tCompare your given name with your nickname (if you don’t have a nickname, invent one for this assignment) by answering the following questions:\n",
    "\n",
    "> a. What is the edit distance between your nickname and your given name?\n",
    "\n",
    "> b. What is the percentage string match between your nickname and your given name?\n",
    "\n",
    "Show your work for both calculations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import Levenshtein\n",
    "import future\n",
    "import TextCleaningToolkit\n",
    "from TextCleaningToolkit import *\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import state_union\n",
    "from nltk import UnigramTagger\n",
    "from nltk import BrillTagger\n",
    "from nltk import BigramTagger\n",
    "from nltk import DefaultTagger\n",
    "from nltk import NgramTagger\n",
    "from nltk import pos_tag##??\n",
    "from nltk import PerceptronTagger\n",
    "from nltk import StanfordPOSTagger\n",
    "from nltk.tag.stanford import CoreNLPNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "wd =os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name = \"Kevin\"\n",
    "NickName = \"Kev\"\n",
    "'''\n",
    "distance is the number of letters that need to be swapped for the Name and nickname to match in my case\n",
    "it is two letters 'i' and 'n'\n",
    "'''\n",
    "Distance = 2 \n",
    "\n",
    "# \"% similarity\"  -  Used levenstein disctance measure to calculate percentage similarity\n",
    "Levenshtein.ratio(Name, NickName)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tFind a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Book: art-of-the-start-guy-kawasaki\n",
    "\n",
    "sentences = \"There are many ways to describe the ebb and flow, yin and yang, bubble blowing \\\n",
    "and bubble bursting phases of business cycles. Here's another one: microscopes and telescopes. \\\n",
    "In the microscope phase, there's a cry for level headed thinking, a return to fundamentals, and going \\\n",
    "'back to basics.'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokens =[]\n",
    "Tokens = Tokens + Tokenizer_Tool(sentences.lower(),'word_tokenize') #plint sentences into tokens\n",
    "words = [word for word in Tokens if word.isalpha()]#Remove punctuations\n",
    "CleanTokens = remove_stopwords(words)#Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['many',\n",
       " 'ways',\n",
       " 'describe',\n",
       " 'ebb',\n",
       " 'flow',\n",
       " 'yin',\n",
       " 'yang',\n",
       " 'bubble',\n",
       " 'blowing',\n",
       " 'bubble',\n",
       " 'bursting',\n",
       " 'phases',\n",
       " 'business',\n",
       " 'cycles',\n",
       " 'another',\n",
       " 'one',\n",
       " 'microscopes',\n",
       " 'telescopes',\n",
       " 'microscope',\n",
       " 'phase',\n",
       " 'cry',\n",
       " 'level',\n",
       " 'headed',\n",
       " 'thinking',\n",
       " 'return',\n",
       " 'fundamentals',\n",
       " 'going',\n",
       " 'basics']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleanTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes\n",
    "\n",
    "My friend was still able to guess what the book was.\n",
    "\n",
    "My friend could  identify the book by me just reading the tokens from the two sentences as he could spot familiar words from the book. He could associate the words in context and descern they are releated to the book art-of-the-start-guy-kawasaki which she had read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tRun one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def stemming(tokens, Type = 'ps', rgxRule ='ing$|s$|ed$', MIN=4):\n",
      "    '''\n",
      "    Code adopted from text Text-analytics-with-python-a-practical-dipanjan-sarkar\n",
      "    this function stems the tokens to get the root\n",
      "    Stemmers: \n",
      "       - LancasterStemmer \n",
      "       - RegexpStemmer #user defined rules\n",
      "       - SnowballStemmer # can stem other languages\n",
      "       - PorterStemmer\n",
      "    '''\n",
      "    stemmers ={'ps':PorterStemmer(), 'ls':LancasterStemmer(),\n",
      "               'sn':SnowballStemmer(\"english\"), 'rg': RegexpStemmer(rgxRule, MIN)}\n",
      "    stemmer = stemmers[Type]\n",
      "    stemmed_list =[]\n",
      "    for i in tokens:\n",
      "        stemmed_list = stemmed_list+[stemmer.stem(i)]\n",
      "    return stemmed_list\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for this question I am using stemming function from my LexicalDiversityToolkit displayed below\n",
    "\n",
    "import inspect\n",
    "code, line_no = inspect.getsourcelines(stemming)\n",
    "print(''.join(code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare stemmers\n",
    "Stemmers_Compare = pd.DataFrame()\n",
    "LancasterStemmer=stemming(CleanTokens, 'ls') #lancasterStemmer\n",
    "RegexpStemmer=stemming(CleanTokens, 'rg') #lancasterStemmer\n",
    "PorterStemmer=stemming(CleanTokens, 'ps') #lancasterStemmer\n",
    "Lema =lemming(CleanTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stemmers_Compare =pd.DataFrame({\"CleanTokens\":CleanTokens,\"LancasterStemmer\":LancasterStemmer,\"RegrexStemmer\": RegexpStemmer,\"PortersStemmer\": PorterStemmer,\"Lematization\":Lema })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CleanTokens</th>\n",
       "      <th>LancasterStemmer</th>\n",
       "      <th>Lematization</th>\n",
       "      <th>PortersStemmer</th>\n",
       "      <th>RegrexStemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>many</td>\n",
       "      <td>many</td>\n",
       "      <td>many</td>\n",
       "      <td>mani</td>\n",
       "      <td>many</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ways</td>\n",
       "      <td>way</td>\n",
       "      <td>way</td>\n",
       "      <td>way</td>\n",
       "      <td>way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>describe</td>\n",
       "      <td>describ</td>\n",
       "      <td>describe</td>\n",
       "      <td>describ</td>\n",
       "      <td>describe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ebb</td>\n",
       "      <td>eb</td>\n",
       "      <td>ebb</td>\n",
       "      <td>ebb</td>\n",
       "      <td>ebb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flow</td>\n",
       "      <td>flow</td>\n",
       "      <td>flow</td>\n",
       "      <td>flow</td>\n",
       "      <td>flow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yin</td>\n",
       "      <td>yin</td>\n",
       "      <td>yin</td>\n",
       "      <td>yin</td>\n",
       "      <td>yin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yang</td>\n",
       "      <td>yang</td>\n",
       "      <td>yang</td>\n",
       "      <td>yang</td>\n",
       "      <td>yang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bubble</td>\n",
       "      <td>bubbl</td>\n",
       "      <td>bubble</td>\n",
       "      <td>bubbl</td>\n",
       "      <td>bubble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>blowing</td>\n",
       "      <td>blow</td>\n",
       "      <td>blowing</td>\n",
       "      <td>blow</td>\n",
       "      <td>blow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bubble</td>\n",
       "      <td>bubbl</td>\n",
       "      <td>bubble</td>\n",
       "      <td>bubbl</td>\n",
       "      <td>bubble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bursting</td>\n",
       "      <td>burst</td>\n",
       "      <td>bursting</td>\n",
       "      <td>burst</td>\n",
       "      <td>burst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phases</td>\n",
       "      <td>phas</td>\n",
       "      <td>phase</td>\n",
       "      <td>phase</td>\n",
       "      <td>phase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>business</td>\n",
       "      <td>busy</td>\n",
       "      <td>business</td>\n",
       "      <td>busi</td>\n",
       "      <td>busines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cycles</td>\n",
       "      <td>cyc</td>\n",
       "      <td>cycle</td>\n",
       "      <td>cycl</td>\n",
       "      <td>cycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>another</td>\n",
       "      <td>anoth</td>\n",
       "      <td>another</td>\n",
       "      <td>anoth</td>\n",
       "      <td>another</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>one</td>\n",
       "      <td>on</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>microscopes</td>\n",
       "      <td>microscop</td>\n",
       "      <td>microscope</td>\n",
       "      <td>microscop</td>\n",
       "      <td>microscope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>telescopes</td>\n",
       "      <td>telescop</td>\n",
       "      <td>telescope</td>\n",
       "      <td>telescop</td>\n",
       "      <td>telescope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>microscope</td>\n",
       "      <td>microscop</td>\n",
       "      <td>microscope</td>\n",
       "      <td>microscop</td>\n",
       "      <td>microscope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>phase</td>\n",
       "      <td>phas</td>\n",
       "      <td>phase</td>\n",
       "      <td>phase</td>\n",
       "      <td>phase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cry</td>\n",
       "      <td>cry</td>\n",
       "      <td>cry</td>\n",
       "      <td>cri</td>\n",
       "      <td>cry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>level</td>\n",
       "      <td>level</td>\n",
       "      <td>level</td>\n",
       "      <td>level</td>\n",
       "      <td>level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>headed</td>\n",
       "      <td>head</td>\n",
       "      <td>head</td>\n",
       "      <td>head</td>\n",
       "      <td>head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>thinking</td>\n",
       "      <td>think</td>\n",
       "      <td>think</td>\n",
       "      <td>think</td>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>return</td>\n",
       "      <td>return</td>\n",
       "      <td>return</td>\n",
       "      <td>return</td>\n",
       "      <td>return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>fundamentals</td>\n",
       "      <td>funda</td>\n",
       "      <td>fundamental</td>\n",
       "      <td>fundament</td>\n",
       "      <td>fundamental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>going</td>\n",
       "      <td>going</td>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>basics</td>\n",
       "      <td>bas</td>\n",
       "      <td>basic</td>\n",
       "      <td>basic</td>\n",
       "      <td>basic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CleanTokens LancasterStemmer Lematization PortersStemmer RegrexStemmer\n",
       "0           many             many         many           mani          many\n",
       "1           ways              way          way            way           way\n",
       "2       describe          describ     describe        describ      describe\n",
       "3            ebb               eb          ebb            ebb           ebb\n",
       "4           flow             flow         flow           flow          flow\n",
       "5            yin              yin          yin            yin           yin\n",
       "6           yang             yang         yang           yang          yang\n",
       "7         bubble            bubbl       bubble          bubbl        bubble\n",
       "8        blowing             blow      blowing           blow          blow\n",
       "9         bubble            bubbl       bubble          bubbl        bubble\n",
       "10      bursting            burst     bursting          burst         burst\n",
       "11        phases             phas        phase          phase         phase\n",
       "12      business             busy     business           busi       busines\n",
       "13        cycles              cyc        cycle           cycl         cycle\n",
       "14       another            anoth      another          anoth       another\n",
       "15           one               on          one            one           one\n",
       "16   microscopes        microscop   microscope      microscop    microscope\n",
       "17    telescopes         telescop    telescope       telescop     telescope\n",
       "18    microscope        microscop   microscope      microscop    microscope\n",
       "19         phase             phas        phase          phase         phase\n",
       "20           cry              cry          cry            cri           cry\n",
       "21         level            level        level          level         level\n",
       "22        headed             head         head           head          head\n",
       "23      thinking            think        think          think         think\n",
       "24        return           return       return         return        return\n",
       "25  fundamentals            funda  fundamental      fundament   fundamental\n",
       "26         going            going           go             go            go\n",
       "27        basics              bas        basic          basic         basic"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stemmers_Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stemmers_Compare.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct from lancaster Stemmer\n",
      "50.0 %\n"
     ]
    }
   ],
   "source": [
    "# lancaster Stemmer\n",
    "n = 28\n",
    "invalid_l = 14\n",
    "print(\"Percentage correct from lancaster Stemmer\")\n",
    "print(100*(n-invalid_l)/n, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct from Regex Stemmer\n",
      "96.42857142857143 %\n"
     ]
    }
   ],
   "source": [
    "#Regex Stemmer\n",
    "invalid_r = 1\n",
    "print(\"Percentage correct from Regex Stemmer\")\n",
    "print(100*(n-invalid_r)/n, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct from porters Stemmer\n",
      "60.714285714285715 %\n"
     ]
    }
   ],
   "source": [
    "#porters Stemmer\n",
    "invalid_p = 11\n",
    "print(\"Percentage correct from porters Stemmer\")\n",
    "print(100*(n-invalid_p)/n, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex is the beststremmer  of the three that I have compared above.\n",
    "\n",
    "I had some issues integrating pattern3 with python 3 to use it a tagger. I installed python 2 in my stem but they were conflicting with python 3 for my Capstone project. I plan to create different environments to be able to switch between python3 and python2 as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework 4**\n",
    "\n",
    "1.\tRun one of the part-of-speech (POS) taggers available in Python. \n",
    "\n",
    "> a. Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Long_sentense = \"In response, I made a conscious and fundamentally bad decision to distance myself from who I was\"\n",
    "tokens_L = nltk.word_tokenize(Long_sentense)\n",
    "Short_sentense =\"The complex houses married and single soldiers and their families.\"\n",
    "tokens_S = nltk.word_tokenize(Short_sentense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Long Sentence ---------\n",
      "In response, I made a conscious and fundamentally bad decision to distance myself from who I was\n",
      "---------Pos Tagging------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('In', 'IN'),\n",
       " ('response', 'NN'),\n",
       " (',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('made', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('conscious', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('fundamentally', 'RB'),\n",
       " ('bad', 'JJ'),\n",
       " ('decision', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('distance', 'VB'),\n",
       " ('myself', 'PRP'),\n",
       " ('from', 'IN'),\n",
       " ('who', 'WP'),\n",
       " ('I', 'PRP'),\n",
       " ('was', 'VBD')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pos tagging Long sentence \n",
    "print('---------Long Sentence ---------')\n",
    "print(Long_sentense)\n",
    "print('---------Pos Tagging------------')\n",
    "nltk.pos_tag(tokens_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b. Find the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Short Sentence----------\n",
      "The complex houses married and single soldiers and their families.\n",
      "---------Pos Tagging---------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('complex', 'JJ'),\n",
       " ('houses', 'NNS'),\n",
       " ('married', 'VBD'),\n",
       " ('and', 'CC'),\n",
       " ('single', 'JJ'),\n",
       " ('soldiers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('their', 'PRP$'),\n",
       " ('families', 'NNS'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pos tagging Long sentence \n",
    "print('---------Short Sentence----------')\n",
    "print(Short_sentense)\n",
    "print('---------Pos Tagging---------------')\n",
    "nltk.pos_tag(tokens_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, \"complex\" is a noun (a housing complex) instead of an adjective, \"houses\" is a verb instead of a noun, and \"married\" is an adjective instead of the past tense of a verb.\n",
    "\n",
    "The corpus used to train the tagger is not similar to my thus  the tagger fails to tag my text because the context, style is all very different.\n",
    "\n",
    "reference: http://mentalfloss.com/article/49238/7-sentences-sound-crazy-are-still-grammatical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tRun a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "\n",
    "> a. Does it produce the same or different output?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_taggers(tokens):\n",
    "    #tokens = nltk.word_tokenize(Long_sentense) #parse sentense\n",
    "    brown_tagged_sents = brown.tagged_sents(categories='news') #training set\n",
    "    summary = {}\n",
    "\n",
    "    unigram_tagger = UnigramTagger(brown_tagged_sents)# train unigram tagger\n",
    "    bigram_tagger = BigramTagger(brown_tagged_sents)# train Bigramtagger\n",
    "    Stanfordpos_tagger = StanfordPOSTagger(wd+'/stanford-postagger/models/wsj-0-18-bidirectional-distsim.tagger',\n",
    "                           wd+'/stanford-postagger/stanford-postagger.jar', encoding='utf-8')\n",
    "\n",
    "    #print(\"-----------\", 'Pos_tagger' ,\"----------------- \")\n",
    "    #print(nltk.pos_tag(tokens),'\\n')\n",
    "    ps = nltk.pos_tag(tokens)\n",
    "    \n",
    "    #print(\"-----------\", 'unigram_tagger' ,\"-----------------\")\n",
    "    #print(unigram_tagger.tag(tokens), '\\n')\n",
    "    un =unigram_tagger.tag(tokens)\n",
    "\n",
    "    #print(\"-----------\", 'StanfordPos _tagger' ,\"----------------- \")\n",
    "    #print(Stanfordpos_tagger.tag(tokens),'\\n')\n",
    "    st = Stanfordpos_tagger.tag(tokens)\n",
    "    \n",
    "    summary.update({'pos_tagger':dict((y, x) for y, x in ps)})\n",
    "    summary.update({'unigram_tagger':dict((y, x) for y, x in un)})\n",
    "    summary.update({'StanfordPos_tagger':dict((y, x) for y, x in st)})\n",
    "    return(pd.DataFrame.from_dict(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "In response, I made a conscious and fundamentally bad decision to distance myself from who I was\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevimwe/anaconda3/lib/python3.6/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StanfordPos_tagger</th>\n",
       "      <th>pos_tagger</th>\n",
       "      <th>unigram_tagger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PPSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conscious</th>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fundamentally</th>\n",
       "      <td>RB</td>\n",
       "      <td>RB</td>\n",
       "      <td>QL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>made</th>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myself</th>\n",
       "      <td>PRP</td>\n",
       "      <td>PRP</td>\n",
       "      <td>PPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>response</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>BEDZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>WP</td>\n",
       "      <td>WP</td>\n",
       "      <td>WPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              StanfordPos_tagger pos_tagger unigram_tagger\n",
       ",                              ,          ,              ,\n",
       "I                            PRP        PRP           PPSS\n",
       "In                            IN         IN             IN\n",
       "a                             DT         DT             AT\n",
       "and                           CC         CC             CC\n",
       "bad                           JJ         JJ             JJ\n",
       "conscious                     JJ         JJ             JJ\n",
       "decision                      NN         NN             NN\n",
       "distance                      VB         VB             NN\n",
       "from                          IN         IN             IN\n",
       "fundamentally                 RB         RB             QL\n",
       "made                         VBD        VBD            VBN\n",
       "myself                       PRP        PRP            PPL\n",
       "response                      NN         NN             NN\n",
       "to                            TO         TO             TO\n",
       "was                          VBD        VBD           BEDZ\n",
       "who                           WP         WP            WPS"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pos tagging Long sentence \n",
    "print('----------------------------------')\n",
    "print(Long_sentense)\n",
    "print('----------------------------------')\n",
    "Compare_taggers(tokens_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "The complex houses married and single soldiers and their families.\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevimwe/anaconda3/lib/python3.6/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StanfordPos_tagger</th>\n",
       "      <th>pos_tagger</th>\n",
       "      <th>unigram_tagger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex</th>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>families</th>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>houses</th>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married</th>\n",
       "      <td>JJ</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soldiers</th>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>their</th>\n",
       "      <td>PRP$</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>PP$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         StanfordPos_tagger pos_tagger unigram_tagger\n",
       ".                         .          .              .\n",
       "The                      DT         DT             AT\n",
       "and                      CC         CC             CC\n",
       "complex                  JJ         JJ             JJ\n",
       "families                NNS        NNS            NNS\n",
       "houses                  NNS        NNS            NNS\n",
       "married                  JJ        VBD            VBN\n",
       "single                   JJ         JJ             AP\n",
       "soldiers                NNS        NNS            NNS\n",
       "their                  PRP$       PRP$            PP$"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pos tagging Short sentence \n",
    "print('----------------------------------')\n",
    "print(Short_sentense)\n",
    "print('----------------------------------')\n",
    "Compare_taggers(tokens_S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different taggers produce different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b. Explain any differences as best you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results could depend on the tag training set used. NLTK.Pos_tagger and StanfordPosTagger are trained and tested on the Wall Street Journal corpus where as Unigram_Tagger that I have is is trained on Brown Corpus.\n",
    "\n",
    "It is interesting that for the the long sentence, the three taggers are able to tag the words the same but for . Unigram_Tagger struggles with the short sentense where are Pos_Tagger and StanfordPosTagger tag the sentence the same which cements our argument the Corpus used is the primary driver of how the Taggers perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tIn a news article from this week’s news, find a random sentence of at least 10 words.\n",
    "\n",
    "> a. Looking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "\n",
    "\n",
    "Ref: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "Article: https://www.cnn.com/2019/02/26/media/att-time-warner-merger-ruling/index.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Leon, the judge who ruled against the Justice Department at trial, was appointed by President George W. Bush.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Leon, the judge who ruled against the Justice Department at trial, was appointed by President George W. Bush.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Leon= NNP,\n",
    "the= DT,\n",
    "judge= NN,\n",
    "who = WP,\n",
    "ruled =VBD,\n",
    "against =IN,\n",
    "the =NN,\n",
    "Justice = NNP,\n",
    "Department =NNP,\n",
    "at = IN,\n",
    "trial=NN,\n",
    "was=VBD,\n",
    "appointed=VBN,\n",
    "by= IN,\n",
    "President= NNP,\n",
    "George  = NNP\n",
    "W. =NNP, \n",
    "Bush=NNP,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b. Now run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_token = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevimwe/anaconda3/lib/python3.6/site-packages/nltk/tag/stanford.py:149: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordPOSTagger, self).__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StanfordPos_tagger</th>\n",
       "      <th>pos_tagger</th>\n",
       "      <th>unigram_tagger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bush</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Department</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN-TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>George</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Justice</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN-TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Leon</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>President</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN-TL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W.</th>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>against</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appointed</th>\n",
       "      <td>VBN</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judge</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruled</th>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>BEDZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who</th>\n",
       "      <td>WP</td>\n",
       "      <td>WP</td>\n",
       "      <td>WPS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           StanfordPos_tagger pos_tagger unigram_tagger\n",
       ",                           ,          ,              ,\n",
       ".                           .          .              .\n",
       "Bush                      NNP        NNP             NP\n",
       "Department                NNP        NNP          NN-TL\n",
       "George                    NNP        NNP             NP\n",
       "Justice                   NNP        NNP          NN-TL\n",
       "Leon                      NNP        NNP             NP\n",
       "President                 NNP        NNP          NN-TL\n",
       "W.                        NNP        NNP             NP\n",
       "against                    IN         IN             IN\n",
       "appointed                 VBN        VBN            VBN\n",
       "at                         IN         IN             IN\n",
       "by                         IN         IN             IN\n",
       "judge                      NN         NN             NN\n",
       "ruled                     VBD        VBD            VBD\n",
       "the                        DT         DT             AT\n",
       "trial                      NN         NN             NN\n",
       "was                       VBD        VBD           BEDZ\n",
       "who                        WP         WP            WPS"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Compare_taggers(sentence_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c. Explain any differences between the two taggers and your manual tagging as much as you can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to explanation in part two, pos_tagger and StanfordPosTagger tag the sentence the same as there were trained on the same Corpus where as unigram_tagger\t has some varition in tags nfor some words compared to the previous two.\n",
    "\n",
    "My tagging and that of the pos_tagger and StanfordPosTagger match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Session info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.8 64bit [GCC 7.3.0]"
        },
        {
         "module": "IPython",
         "version": "7.2.0"
        },
        {
         "module": "OS",
         "version": "Linux 4.15.0 46 generic x86_64 with debian buster sid"
        },
        {
         "module": "pandas",
         "version": "0.20.3"
        },
        {
         "module": "numpy",
         "version": "1.15.0"
        },
        {
         "module": "nltk",
         "version": "3.2.5"
        },
        {
         "module": "re",
         "version": "2.2.1"
        },
        {
         "module": "contractions",
         "version": "0.0.17"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.8 64bit [GCC 7.3.0]</td></tr><tr><td>IPython</td><td>7.2.0</td></tr><tr><td>OS</td><td>Linux 4.15.0 46 generic x86_64 with debian buster sid</td></tr><tr><td>pandas</td><td>0.20.3</td></tr><tr><td>numpy</td><td>1.15.0</td></tr><tr><td>nltk</td><td>3.2.5</td></tr><tr><td>re</td><td>2.2.1</td></tr><tr><td>contractions</td><td>0.0.17</td></tr><tr><td colspan='2'>Sun Mar 31 18:27:14 2019 CDT</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.8 64bit [GCC 7.3.0] \\\\ \\hline\n",
       "IPython & 7.2.0 \\\\ \\hline\n",
       "OS & Linux 4.15.0 46 generic x86\\_64 with debian buster sid \\\\ \\hline\n",
       "pandas & 0.20.3 \\\\ \\hline\n",
       "numpy & 1.15.0 \\\\ \\hline\n",
       "nltk & 3.2.5 \\\\ \\hline\n",
       "re & 2.2.1 \\\\ \\hline\n",
       "contractions & 0.0.17 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Sun Mar 31 18:27:14 2019 CDT} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.8 64bit [GCC 7.3.0]\n",
       "IPython 7.2.0\n",
       "OS Linux 4.15.0 46 generic x86_64 with debian buster sid\n",
       "pandas 0.20.3\n",
       "numpy 1.15.0\n",
       "nltk 3.2.5\n",
       "re 2.2.1\n",
       "contractions 0.0.17\n",
       "Sun Mar 31 18:27:14 2019 CDT"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information pandas, numpy, nltk, re, contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
